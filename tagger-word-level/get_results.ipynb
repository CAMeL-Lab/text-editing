{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from get_best_checkpoint import get_best_checkpoint_gec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer, Prune, Prune >> Proc, K, PnxSep, Decoding Iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir(tokenizer_var=None, prune=False, prune_cor=False, k=10, pnx_sep=False, morph=False, decoding_iter=1, dataset='qalb14'):\n",
    "    if pnx_sep == False:\n",
    "        m2_file = f'dev.txt.{decoding_iter}.m2'\n",
    "        model_dir = ''\n",
    "        if prune and prune_cor:\n",
    "            model_dir = f'prune_{k}_cor'\n",
    "            model_dir += (f'/{dataset}_{tokenizer_var}' if tokenizer_var else f'/{dataset}')\n",
    "        elif prune:\n",
    "            model_dir = f'prune_{k}'\n",
    "            model_dir += (f'/{dataset}_{tokenizer_var}' if tokenizer_var else f'/{dataset}')\n",
    "\n",
    "        elif prune == False and prune_cor == False:\n",
    "            model_dir = (f'qalb14_{tokenizer_var}' if tokenizer_var else f'{dataset}')\n",
    "\n",
    "    else:\n",
    "\n",
    "        model_dir = 'pnx_sep' if morph else 'pnx'\n",
    "\n",
    "        # m2_file = f'dev.txt.nopnx_edit.{decoding_iter}.nopnx.m2'\n",
    "        # m2_file = f'dev.txt.{decoding_iter}.nopnx.m2'\n",
    "        m2_file = f'dev.txt.{decoding_iter}.m2'\n",
    "\n",
    "        if prune and prune_cor:\n",
    "            if '_s1234' in model_dir or '_mt' in model_dir:\n",
    "                model_dir = model_dir.replace('_s1234', '').replace('_mt', '')\n",
    "            model_dir += f'_prune_{k}_cor'\n",
    "        elif prune:\n",
    "            if '_s1234' in model_dir or '_mt' in model_dir:\n",
    "                model_dir = model_dir.replace('_s1234', '').replace('_mt', '')\n",
    "            model_dir += f'_prune_{k}'\n",
    "            # model_dir += f'_prune_{k}_s1234'\n",
    "            # model_dir += f'_prune_{k}_mt'\n",
    "        \n",
    "        if morph:\n",
    "            model_dir += (f'/nopnx/{dataset}_{tokenizer_var}' if tokenizer_var else f'/nopnx/{dataset}')\n",
    "        else:\n",
    "            model_dir += (f'/{dataset}_{tokenizer_var}' if tokenizer_var else f'/')\n",
    "\n",
    "    if morph:\n",
    "        model_dir = f'taggers+morph/{model_dir}'\n",
    "    else:\n",
    "        if pnx_sep:\n",
    "            model_dir = f'pnx_taggers/{model_dir}'\n",
    "        else:\n",
    "            model_dir = f'taggers/{model_dir}'\n",
    "\n",
    "\n",
    "    model_dir = f'/scratch/ba63/arabic-text-editing/gec_taggers/{dataset}/' + model_dir\n",
    "    \n",
    "    return model_dir, m2_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizers = [None, 5, 4, 3]\n",
    "# prune = [True, False]\n",
    "# prune_cor = [True, False]\n",
    "# k = [None, 10, 20, 30]\n",
    "# pnx_sep = [True, False]\n",
    "# iterations = [1, 2, 3]\n",
    "# morph = [True, False]\n",
    "\n",
    "# print(f'Tokenizer\\tPrune @ K\\tPrune @ K >> Preproc\\tK\\tPnx Sep\\tMorph\\tDecoding Iter\\t\\tP\\tR\\tF1\\tF0.5\\tP(NoPnx)\\tR(NoPnx)\\tF1(NoPnx)\\tF0.5(NoPnx)')\n",
    "# for args in product(*[tokenizers, prune, prune_cor, k, pnx_sep, morph, iterations]):\n",
    "#     kwargs = {'tokenizer_var': args[0], 'prune':args[1], 'prune_cor': args[2], 'k': args[3], 'pnx_sep' :args[4], 'morph': args[5],\n",
    "#              'decoding_iter': args[6]}\n",
    "    \n",
    "#     if kwargs['prune'] == False and kwargs['prune_cor'] == True:\n",
    "#         continue\n",
    "\n",
    "#     if kwargs['prune'] == False and kwargs['prune_cor'] == False and kwargs['k'] != None:\n",
    "#         continue\n",
    "    \n",
    "#     if kwargs['k'] == None and (kwargs['prune'] != False or kwargs['prune_cor'] != False):\n",
    "#         continue\n",
    "\n",
    "#     model_dir, m2_file = get_dir(**kwargs)\n",
    "\n",
    "#     # print(model_dir, m2_file)\n",
    "#     m2_results = get_best_checkpoint_gec(model_path=model_dir, m2_file_name=m2_file)\n",
    "#     m2score = m2_results['m2score']\n",
    "#     m2_score_nopnx = m2_results['m2score_nopnx']\n",
    "\n",
    "#     exp = '\\t'.join([str(v) for v in kwargs.values()])\n",
    "#     p, r, f1, f05 = m2score['p'], m2score['r'], m2score['f1'], m2score['f0.5']\n",
    "#     p_nopnx, r_nopnx, f1_nopnx, f05_nopnx = m2_score_nopnx['p'], m2_score_nopnx['r'], m2_score_nopnx['f1'], m2_score_nopnx['f0.5']\n",
    "#     print(f'{exp}\\t\\t{p}\\t{r}\\t{f1}\\t{f05}\\t{p_nopnx}\\t{r_nopnx}\\t{f1_nopnx}\\t{f05_nopnx}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizers = [None, 5, 4, 3]\n",
    "# prune = [True, False]\n",
    "# prune_cor = [True, False]\n",
    "# k = [None, 10, 20, 30]\n",
    "# pnx_sep = [True]\n",
    "# iterations = [1, 2, 3]\n",
    "# morph = [False]\n",
    "\n",
    "# print(f'Tokenizer\\tPrune @ K\\tPrune @ K >> Preproc\\tK\\tPnx Sep\\tMorph\\tDecoding Iter\\t\\tP\\tR\\tF1\\tF0.5')\n",
    "# for args in product(*[tokenizers, prune, prune_cor, k, pnx_sep, morph, iterations]):\n",
    "#     kwargs = {'tokenizer_var': args[0], 'prune':args[1], 'prune_cor': args[2], 'k': args[3], 'pnx_sep' :args[4], 'morph': args[5],\n",
    "#              'decoding_iter': args[6]}\n",
    "    \n",
    "#     if kwargs['prune'] == False and kwargs['prune_cor'] == True:\n",
    "#         continue\n",
    "\n",
    "#     if kwargs['prune'] == False and kwargs['prune_cor'] == False and kwargs['k'] != None:\n",
    "#         continue\n",
    "    \n",
    "#     if kwargs['k'] == None and (kwargs['prune'] != False or kwargs['prune_cor'] != False):\n",
    "#         continue\n",
    "\n",
    "#     model_dir, m2_file = get_dir(**kwargs)\n",
    "\n",
    "#     # print(model_dir, m2_file)\n",
    "#     m2_results = get_best_checkpoint_gec(model_path=model_dir, m2_file_name=m2_file, add_nopnx_eval=False)\n",
    "#     m2score = m2_results['m2score']\n",
    "\n",
    "#     exp = '\\t'.join([str(v) for v in kwargs.values()])\n",
    "#     p, r, f1, f05 = m2score['p'], m2score['r'], m2score['f1'], m2score['f0.5']\n",
    "#     print(f'{exp}\\t\\t{p}\\t{r}\\t{f1}\\t{f05}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer\tPrune @ K\tPrune @ K >> Preproc\tK\tPnx Sep\tMorph\tDecoding Iter\t\tP\tR\tF1\tF0.5\n",
      "None\tTrue\tFalse\t10\tTrue\tFalse\t1\t\t0.8904\t0.8356\t0.8621\t0.8788\n",
      "None\tTrue\tFalse\t10\tTrue\tFalse\t2\t\t0.8885\t0.8369\t0.8619\t0.8777\n",
      "None\tTrue\tFalse\t10\tTrue\tFalse\t3\t\t0.8884\t0.8370\t0.8619\t0.8776\n",
      "None\tTrue\tFalse\t20\tTrue\tFalse\t1\t\t0.8935\t0.8357\t0.8636\t0.8813\n",
      "None\tTrue\tFalse\t20\tTrue\tFalse\t2\t\t0.8910\t0.8380\t0.8637\t0.8799\n",
      "None\tTrue\tFalse\t20\tTrue\tFalse\t3\t\t0.8909\t0.8382\t0.8637\t0.8798\n",
      "None\tTrue\tFalse\t30\tTrue\tFalse\t1\t\t0.8924\t0.8334\t0.8619\t0.8799\n",
      "None\tTrue\tFalse\t30\tTrue\tFalse\t2\t\t0.8902\t0.8348\t0.8616\t0.8786\n",
      "None\tTrue\tFalse\t30\tTrue\tFalse\t3\t\t0.8902\t0.8348\t0.8616\t0.8785\n",
      "None\tFalse\tFalse\tNone\tTrue\tFalse\t1\t\t0.8855\t0.8389\t0.8616\t0.8758\n",
      "None\tFalse\tFalse\tNone\tTrue\tFalse\t2\t\t0.8840\t0.8400\t0.8614\t0.8748\n",
      "None\tFalse\tFalse\tNone\tTrue\tFalse\t3\t\t0.8840\t0.8400\t0.8614\t0.8748\n",
      "5\tTrue\tFalse\t10\tTrue\tFalse\t1\t\t0.8875\t0.8391\t0.8626\t0.8774\n",
      "5\tTrue\tFalse\t10\tTrue\tFalse\t2\t\t0.8846\t0.8421\t0.8628\t0.8757\n",
      "5\tTrue\tFalse\t10\tTrue\tFalse\t3\t\t0.8846\t0.8422\t0.8629\t0.8757\n",
      "5\tTrue\tFalse\t20\tTrue\tFalse\t1\t\t0.8873\t0.8386\t0.8623\t0.8771\n",
      "5\tTrue\tFalse\t20\tTrue\tFalse\t2\t\t0.8830\t0.8416\t0.8618\t0.8744\n",
      "5\tTrue\tFalse\t20\tTrue\tFalse\t3\t\t0.8828\t0.8418\t0.8618\t0.8743\n",
      "5\tTrue\tFalse\t30\tTrue\tFalse\t1\t\t0.8875\t0.8393\t0.8627\t0.8774\n",
      "5\tTrue\tFalse\t30\tTrue\tFalse\t2\t\t0.8851\t0.8423\t0.8632\t0.8762\n",
      "5\tTrue\tFalse\t30\tTrue\tFalse\t3\t\t0.8850\t0.8423\t0.8631\t0.8761\n",
      "5\tFalse\tFalse\tNone\tTrue\tFalse\t1\t\t0.8877\t0.8379\t0.8621\t0.8773\n",
      "5\tFalse\tFalse\tNone\tTrue\tFalse\t2\t\t0.8854\t0.8396\t0.8619\t0.8758\n",
      "5\tFalse\tFalse\tNone\tTrue\tFalse\t3\t\t0.8853\t0.8397\t0.8619\t0.8758\n",
      "4\tTrue\tFalse\t10\tTrue\tFalse\t1\t\t0.8846\t0.8391\t0.8613\t0.8751\n",
      "4\tTrue\tFalse\t10\tTrue\tFalse\t2\t\t0.8818\t0.8423\t0.8616\t0.8736\n",
      "4\tTrue\tFalse\t10\tTrue\tFalse\t3\t\t0.8817\t0.8422\t0.8615\t0.8735\n",
      "4\tTrue\tFalse\t20\tTrue\tFalse\t1\t\t0.8881\t0.8345\t0.8605\t0.8769\n",
      "4\tTrue\tFalse\t20\tTrue\tFalse\t2\t\t0.8851\t0.8386\t0.8613\t0.8754\n",
      "4\tTrue\tFalse\t20\tTrue\tFalse\t3\t\t0.8850\t0.8386\t0.8612\t0.8753\n",
      "4\tTrue\tFalse\t30\tTrue\tFalse\t1\t\t0.8885\t0.8365\t0.8617\t0.8776\n",
      "4\tTrue\tFalse\t30\tTrue\tFalse\t2\t\t0.8851\t0.8395\t0.8617\t0.8756\n",
      "4\tTrue\tFalse\t30\tTrue\tFalse\t3\t\t0.8850\t0.8395\t0.8617\t0.8755\n",
      "4\tFalse\tFalse\tNone\tTrue\tFalse\t1\t\t0.8856\t0.8417\t0.8631\t0.8764\n",
      "4\tFalse\tFalse\tNone\tTrue\tFalse\t2\t\t0.8846\t0.8389\t0.8612\t0.8751\n",
      "4\tFalse\tFalse\tNone\tTrue\tFalse\t3\t\t0.8846\t0.8390\t0.8612\t0.8751\n",
      "3\tTrue\tFalse\t10\tTrue\tFalse\t1\t\t0.8921\t0.8253\t0.8574\t0.8779\n",
      "3\tTrue\tFalse\t10\tTrue\tFalse\t2\t\t0.8890\t0.8295\t0.8582\t0.8765\n",
      "3\tTrue\tFalse\t10\tTrue\tFalse\t3\t\t0.8890\t0.8295\t0.8582\t0.8764\n",
      "3\tTrue\tFalse\t20\tTrue\tFalse\t1\t\t0.8940\t0.8268\t0.8591\t0.8797\n",
      "3\tTrue\tFalse\t20\tTrue\tFalse\t2\t\t0.8900\t0.8313\t0.8596\t0.8776\n",
      "3\tTrue\tFalse\t20\tTrue\tFalse\t3\t\t0.8900\t0.8314\t0.8597\t0.8777\n",
      "3\tTrue\tFalse\t30\tTrue\tFalse\t1\t\t0.8891\t0.8308\t0.8590\t0.8768\n",
      "3\tTrue\tFalse\t30\tTrue\tFalse\t2\t\t0.8861\t0.8344\t0.8595\t0.8753\n",
      "3\tTrue\tFalse\t30\tTrue\tFalse\t3\t\t0.8860\t0.8345\t0.8595\t0.8752\n",
      "3\tFalse\tFalse\tNone\tTrue\tFalse\t1\t\t0.8877\t0.8342\t0.8601\t0.8765\n",
      "3\tFalse\tFalse\tNone\tTrue\tFalse\t2\t\t0.8854\t0.8381\t0.8611\t0.8755\n",
      "3\tFalse\tFalse\tNone\tTrue\tFalse\t3\t\t0.8854\t0.8381\t0.8611\t0.8755\n"
     ]
    }
   ],
   "source": [
    "tokenizers = [None, 5, 4, 3]\n",
    "prune = [True, False]\n",
    "prune_cor = [False]\n",
    "k = [None, 10, 20, 30]\n",
    "pnx_sep = [True]\n",
    "iterations = [1, 2, 3]\n",
    "morph = [False]\n",
    "\n",
    "print(f'Tokenizer\\tPrune @ K\\tPrune @ K >> Preproc\\tK\\tPnx Sep\\tMorph\\tDecoding Iter\\t\\tP\\tR\\tF1\\tF0.5')\n",
    "for args in product(*[tokenizers, prune, prune_cor, k, pnx_sep, morph, iterations]):\n",
    "    kwargs = {'tokenizer_var': args[0], 'prune':args[1], 'prune_cor': args[2], 'k': args[3], 'pnx_sep' :args[4], 'morph': args[5],\n",
    "             'decoding_iter': args[6]}\n",
    "    \n",
    "    if kwargs['prune'] == False and kwargs['prune_cor'] == True:\n",
    "        continue\n",
    "\n",
    "    if kwargs['prune'] == False and kwargs['prune_cor'] == False and kwargs['k'] != None:\n",
    "        continue\n",
    "    \n",
    "    if kwargs['k'] == None and (kwargs['prune'] != False or kwargs['prune_cor'] != False):\n",
    "        continue\n",
    "\n",
    "    model_dir, m2_file = get_dir(**kwargs)\n",
    "    # print(model_dir, m2_file)\n",
    "    m2_results = get_best_checkpoint_gec(model_path=model_dir, m2_file_name=m2_file, add_nopnx_eval=False)\n",
    "    m2score = m2_results['m2score']\n",
    "\n",
    "    exp = '\\t'.join([str(v) for v in kwargs.values()])\n",
    "    p, r, f1, f05 = m2score['p'], m2score['r'], m2score['f1'], m2score['f0.5']\n",
    "    print(f'{exp}\\t\\t{p}\\t{r}\\t{f1}\\t{f05}') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer\tPrune @ K\tPrune @ K >> Preproc\tK\tPnx Sep\tMorph\tDecoding Iter\t\tP\tR\tF1\tF0.5\n",
      "None\tTrue\tFalse\t10\tTrue\tFalse\t1\t\t0.8828\t0.7563\t0.8147\t0.8543\n",
      "None\tTrue\tFalse\t10\tTrue\tFalse\t2\t\t0.8843\t0.7599\t0.8173\t0.8562\n",
      "None\tTrue\tFalse\t10\tTrue\tFalse\t3\t\t0.8805\t0.7661\t0.8194\t0.8550\n",
      "None\tTrue\tFalse\t20\tTrue\tFalse\t1\t\t0.8751\t0.7536\t0.8098\t0.8478\n",
      "None\tTrue\tFalse\t20\tTrue\tFalse\t2\t\t0.8831\t0.7581\t0.8158\t0.8549\n",
      "None\tTrue\tFalse\t20\tTrue\tFalse\t3\t\t0.8804\t0.7652\t0.8188\t0.8547\n",
      "None\tTrue\tFalse\t30\tTrue\tFalse\t1\t\t0.8792\t0.7500\t0.8095\t0.8499\n",
      "None\tTrue\tFalse\t30\tTrue\tFalse\t2\t\t0.8837\t0.7625\t0.8187\t0.8565\n",
      "None\tTrue\tFalse\t30\tTrue\tFalse\t3\t\t0.8879\t0.7661\t0.8225\t0.8605\n",
      "None\tFalse\tFalse\tNone\tTrue\tFalse\t1\t\t0.8772\t0.7491\t0.8081\t0.8482\n",
      "None\tFalse\tFalse\tNone\tTrue\tFalse\t2\t\t0.8802\t0.7572\t0.8141\t0.8525\n",
      "None\tFalse\tFalse\tNone\tTrue\tFalse\t3\t\t0.8805\t0.7590\t0.8152\t0.8531\n"
     ]
    }
   ],
   "source": [
    "tokenizers = [None]\n",
    "prune = [True, False]\n",
    "prune_cor = [False]\n",
    "k = [None, 10, 20, 30]\n",
    "pnx_sep = [True]\n",
    "iterations = [1, 2, 3]\n",
    "morph = [False]\n",
    "\n",
    "print(f'Tokenizer\\tPrune @ K\\tPrune @ K >> Preproc\\tK\\tPnx Sep\\tMorph\\tDecoding Iter\\t\\tP\\tR\\tF1\\tF0.5')\n",
    "for args in product(*[tokenizers, prune, prune_cor, k, pnx_sep, morph, iterations]):\n",
    "    kwargs = {'tokenizer_var': args[0], 'prune':args[1], 'prune_cor': args[2], 'k': args[3], 'pnx_sep' :args[4], 'morph': args[5],\n",
    "             'decoding_iter': args[6]}\n",
    "    \n",
    "    if kwargs['prune'] == False and kwargs['prune_cor'] == True:\n",
    "        continue\n",
    "\n",
    "    if kwargs['prune'] == False and kwargs['prune_cor'] == False and kwargs['k'] != None:\n",
    "        continue\n",
    "    \n",
    "    if kwargs['k'] == None and (kwargs['prune'] != False or kwargs['prune_cor'] != False):\n",
    "        continue\n",
    "\n",
    "    model_dir, m2_file = get_dir(**kwargs, dataset='qalb14+zaebuc_x10')\n",
    "    m2_results = get_best_checkpoint_gec(model_path=model_dir, m2_file_name=m2_file, add_nopnx_eval=False)\n",
    "    m2score = m2_results['m2score']\n",
    "\n",
    "    exp = '\\t'.join([str(v) for v in kwargs.values()])\n",
    "    p, r, f1, f05 = m2score['p'], m2score['r'], m2score['f1'], m2score['f0.5']\n",
    "    print(f'{exp}\\t\\t{p}\\t{r}\\t{f1}\\t{f05}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer\tPrune @ K\tPrune @ K >> Preproc\tK\tPnx Sep\tMorph\tDecoding Iter\t\tP\tR\tF1\tF0.5\n",
      "None\tTrue\tFalse\t10\tTrue\tFalse\t1\t\t0.9685\t0.9388\t0.9534\t0.9624\n",
      "None\tTrue\tFalse\t10\tTrue\tFalse\t2\t\t0.9677\t0.9381\t0.9526\t0.9616\n",
      "None\tTrue\tFalse\t10\tTrue\tFalse\t3\t\t0.9677\t0.9388\t0.9530\t0.9618\n",
      "None\tTrue\tFalse\t20\tTrue\tFalse\t1\t\t0.9706\t0.9350\t0.9525\t0.9633\n",
      "None\tTrue\tFalse\t20\tTrue\tFalse\t2\t\t0.9684\t0.9365\t0.9522\t0.9618\n",
      "None\tTrue\tFalse\t20\tTrue\tFalse\t3\t\t0.9684\t0.9365\t0.9522\t0.9618\n",
      "None\tTrue\tFalse\t30\tTrue\tFalse\t1\t\t0.9633\t0.9427\t0.9529\t0.9591\n",
      "None\tTrue\tFalse\t30\tTrue\tFalse\t2\t\t0.9626\t0.9442\t0.9533\t0.9589\n",
      "None\tTrue\tFalse\t30\tTrue\tFalse\t3\t\t0.9626\t0.9442\t0.9533\t0.9589\n",
      "None\tFalse\tFalse\tNone\tTrue\tFalse\t1\t\t0.9654\t0.9388\t0.9519\t0.9600\n",
      "None\tFalse\tFalse\tNone\tTrue\tFalse\t2\t\t0.9647\t0.9411\t0.9528\t0.9599\n",
      "None\tFalse\tFalse\tNone\tTrue\tFalse\t3\t\t0.9647\t0.9411\t0.9528\t0.9599\n"
     ]
    }
   ],
   "source": [
    "tokenizers = [None]\n",
    "prune = [True, False]\n",
    "prune_cor = [False]\n",
    "k = [None, 10, 20, 30]\n",
    "pnx_sep = [True]\n",
    "iterations = [1, 2, 3]\n",
    "morph = [False]\n",
    "\n",
    "print(f'Tokenizer\\tPrune @ K\\tPrune @ K >> Preproc\\tK\\tPnx Sep\\tMorph\\tDecoding Iter\\t\\tP\\tR\\tF1\\tF0.5')\n",
    "for args in product(*[tokenizers, prune, prune_cor, k, pnx_sep, morph, iterations]):\n",
    "    kwargs = {'tokenizer_var': args[0], 'prune':args[1], 'prune_cor': args[2], 'k': args[3], 'pnx_sep' :args[4], 'morph': args[5],\n",
    "             'decoding_iter': args[6]}\n",
    "    \n",
    "    if kwargs['prune'] == False and kwargs['prune_cor'] == True:\n",
    "        continue\n",
    "\n",
    "    if kwargs['prune'] == False and kwargs['prune_cor'] == False and kwargs['k'] != None:\n",
    "        continue\n",
    "    \n",
    "    if kwargs['k'] == None and (kwargs['prune'] != False or kwargs['prune_cor'] != False):\n",
    "        continue\n",
    "\n",
    "    model_dir, m2_file = get_dir(**kwargs, dataset='qalb14_adj+zaebuc_x10')\n",
    "    m2_results = get_best_checkpoint_gec(model_path=model_dir, m2_file_name=m2_file, add_nopnx_eval=False)\n",
    "    m2score = m2_results['m2score']\n",
    "\n",
    "    exp = '\\t'.join([str(v) for v in kwargs.values()])\n",
    "    p, r, f1, f05 = m2score['p'], m2score['r'], m2score['f1'], m2score['f0.5']\n",
    "    print(f'{exp}\\t\\t{p}\\t{r}\\t{f1}\\t{f05}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simplification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
